{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "notify_time": "30",
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "591px",
        "left": "320.2px",
        "right": "100.867px",
        "top": "167px",
        "width": "654px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Bird_classification_BCNN .ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpMlFSH5M9w9",
        "colab_type": "code",
        "outputId": "05600eb5-f5dc-4c1d-cb9c-fb69132661fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.1.0\n",
        "!pip install keras==2.3.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.17.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.1.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.27.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.34.2)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.8.1)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu==2.1.0) (45.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (2.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n",
            "Collecting keras==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.17.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.1.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf-lV3ARwxVR",
        "colab_type": "code",
        "outputId": "a1cd70f8-91c4-4132-927e-d444bdcfe39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpYhXBVLMhtS",
        "colab_type": "text"
      },
      "source": [
        "# load dependencies, set configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoQliie6MhtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "# %load_ext jupyternotify\n",
        "# %autonotify -a 30\n",
        "\n",
        "import math\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "import keras.layers\n",
        "import keras.applications\n",
        "import keras.backend\n",
        "import keras.preprocessing.image\n",
        "import keras.utils\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "import shutil\n",
        "\n",
        "\n",
        "# configurations\n",
        "\n",
        "## seeding\n",
        "os.environ['PYTHONHASHSEED'] = '3'\n",
        "np.random.seed(3)\n",
        "random.seed(3)\n",
        "#tf.set_random_seed(3)\n",
        "\n",
        "# ## which gpu to use\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "## memory allocation\n",
        "#config = tf.ConfigProto()\n",
        "#config.gpu_options.allow_growth = True\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "#session = tf.Session(config=config)\n",
        "#keras.backend.set_session(session)\n",
        "\n",
        "## data directory for CUB200 root\n",
        "PATH_DATA_ROOT_CUB200 = \"/content/gdrive/My Drive/BCNN/BCNN_keras-master/images\"\n",
        "\n",
        "## network configurations\n",
        "### number of output classes, 200 for CUB200\n",
        "NO_CLASS = 200\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIzP8o4sNkym",
        "colab_type": "code",
        "outputId": "b36941d2-b554-4725-afeb-69640b89d76c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnZizERRMhth",
        "colab_type": "code",
        "outputId": "27155362-0e0d-439a-c5c0-ca6f9b9b829c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4aKbYymMhtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## which gpu to use\n",
        "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoyYggkQMhtp",
        "colab_type": "text"
      },
      "source": [
        "# split CUB200 into train, valid "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAQTAy48N5a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "def img_train_test_split(img_source_dir, train_size):\n",
        "    \"\"\"\n",
        "    Randomly splits images over a train and validation folder, while preserving the folder structure\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    img_source_dir : string\n",
        "        Path to the folder with the images to be split. Can be absolute or relative path   \n",
        "        \n",
        "    train_size : float\n",
        "        Proportion of the original images that need to be copied in the subdirectory in the train folder\n",
        "    \"\"\"    \n",
        "    if not (isinstance(img_source_dir, str)):\n",
        "        raise AttributeError('img_source_dir must be a string')\n",
        "        \n",
        "    if not os.path.exists(img_source_dir):\n",
        "        raise OSError('img_source_dir does not exist')\n",
        "        \n",
        "    if not (isinstance(train_size, float)):\n",
        "        raise AttributeError('train_size must be a float')\n",
        "        \n",
        "    # Set up empty folder structure if not exists\n",
        "    if not os.path.exists('data'):\n",
        "        os.makedirs('data')\n",
        "    else:\n",
        "        if not os.path.exists('data/train'):\n",
        "            os.makedirs('data/train')\n",
        "        if not os.path.exists('data/valid'):\n",
        "            os.makedirs('data/valid')\n",
        "            \n",
        "    # Get the subdirectories in the main image folder\n",
        "    subdirs = [subdir for subdir in os.listdir(img_source_dir) if os.path.isdir(os.path.join(img_source_dir, subdir))]\n",
        "\n",
        "    for subdir in subdirs:\n",
        "        subdir_fullpath = os.path.join(img_source_dir, subdir)\n",
        "        if len(os.listdir(subdir_fullpath)) == 0:\n",
        "            print(subdir_fullpath + ' is empty')\n",
        "            break\n",
        "\n",
        "        train_subdir = os.path.join('data/train', subdir)\n",
        "        validation_subdir = os.path.join('data/valid', subdir)\n",
        "\n",
        "        # Create subdirectories in train and validation folders\n",
        "        if not os.path.exists(train_subdir):\n",
        "            os.makedirs(train_subdir)\n",
        "\n",
        "        if not os.path.exists(validation_subdir):\n",
        "            os.makedirs(validation_subdir)\n",
        "\n",
        "        train_counter = 0\n",
        "        validation_counter = 0\n",
        "\n",
        "        # Randomly assign an image to train or validation folder\n",
        "        for filename in os.listdir(subdir_fullpath):\n",
        "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
        "                fileparts = filename.split('.')\n",
        "\n",
        "                if random.uniform(0, 1) <= train_size:\n",
        "                    copyfile(os.path.join(subdir_fullpath, filename), os.path.join(train_subdir, str(train_counter) + '.' + fileparts[1]))\n",
        "                    train_counter += 1\n",
        "                else:\n",
        "                    copyfile(os.path.join(subdir_fullpath, filename), os.path.join(validation_subdir, str(validation_counter) + '.' + fileparts[1]))\n",
        "                    validation_counter += 1\n",
        "                    \n",
        "        print('Copied ' + str(train_counter) + ' images to data/train/' + subdir)\n",
        "        print('Copied ' + str(validation_counter) + ' images to data/valid/' + subdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdN8Rse9ODzg",
        "colab_type": "code",
        "outputId": "f8aaf7a0-1650-4c0c-a357-ce453b07cd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_path = '/content/gdrive/My Drive/BCNN/BCNN_keras-master/images/images'\n",
        "img_train_test_split(img_source_dir = data_path, train_size = 0.60)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copied 28 images to data/train/196.House_Wren\n",
            "Copied 22 images to data/valid/196.House_Wren\n",
            "Copied 24 images to data/train/194.Cactus_Wren\n",
            "Copied 24 images to data/valid/194.Cactus_Wren\n",
            "Copied 45 images to data/train/195.Carolina_Wren\n",
            "Copied 21 images to data/valid/195.Carolina_Wren\n",
            "Copied 28 images to data/train/198.Rock_Wren\n",
            "Copied 22 images to data/valid/198.Rock_Wren\n",
            "Copied 30 images to data/train/200.Common_Yellowthroat\n",
            "Copied 16 images to data/valid/200.Common_Yellowthroat\n",
            "Copied 41 images to data/train/199.Winter_Wren\n",
            "Copied 31 images to data/valid/199.Winter_Wren\n",
            "Copied 40 images to data/train/197.Marsh_Wren\n",
            "Copied 24 images to data/valid/197.Marsh_Wren\n",
            "Copied 34 images to data/train/191.Red_headed_Woodpecker\n",
            "Copied 24 images to data/valid/191.Red_headed_Woodpecker\n",
            "Copied 45 images to data/train/192.Downy_Woodpecker\n",
            "Copied 31 images to data/valid/192.Downy_Woodpecker\n",
            "Copied 43 images to data/train/193.Bewick_Wren\n",
            "Copied 25 images to data/valid/193.Bewick_Wren\n",
            "Copied 52 images to data/train/188.Pileated_Woodpecker\n",
            "Copied 26 images to data/valid/188.Pileated_Woodpecker\n",
            "Copied 44 images to data/train/185.Bohemian_Waxwing\n",
            "Copied 30 images to data/valid/185.Bohemian_Waxwing\n",
            "Copied 23 images to data/train/190.Red_cockaded_Woodpecker\n",
            "Copied 21 images to data/valid/190.Red_cockaded_Woodpecker\n",
            "Copied 42 images to data/train/187.American_Three_toed_Woodpecker\n",
            "Copied 16 images to data/valid/187.American_Three_toed_Woodpecker\n",
            "Copied 34 images to data/train/186.Cedar_Waxwing\n",
            "Copied 32 images to data/valid/186.Cedar_Waxwing\n",
            "Copied 49 images to data/train/189.Red_bellied_Woodpecker\n",
            "Copied 25 images to data/valid/189.Red_bellied_Woodpecker\n",
            "Copied 32 images to data/train/184.Louisiana_Waterthrush\n",
            "Copied 26 images to data/valid/184.Louisiana_Waterthrush\n",
            "Copied 46 images to data/train/183.Northern_Waterthrush\n",
            "Copied 26 images to data/valid/183.Northern_Waterthrush\n",
            "Copied 45 images to data/train/181.Worm_eating_Warbler\n",
            "Copied 19 images to data/valid/181.Worm_eating_Warbler\n",
            "Copied 25 images to data/train/182.Yellow_Warbler\n",
            "Copied 17 images to data/valid/182.Yellow_Warbler\n",
            "Copied 46 images to data/train/180.Wilson_Warbler\n",
            "Copied 24 images to data/valid/180.Wilson_Warbler\n",
            "Copied 42 images to data/train/177.Prothonotary_Warbler\n",
            "Copied 28 images to data/valid/177.Prothonotary_Warbler\n",
            "Copied 44 images to data/train/174.Palm_Warbler\n",
            "Copied 18 images to data/valid/174.Palm_Warbler\n",
            "Copied 41 images to data/train/173.Orange_crowned_Warbler\n",
            "Copied 21 images to data/valid/173.Orange_crowned_Warbler\n",
            "Copied 30 images to data/train/178.Swainson_Warbler\n",
            "Copied 20 images to data/valid/178.Swainson_Warbler\n",
            "Copied 51 images to data/train/176.Prairie_Warbler\n",
            "Copied 21 images to data/valid/176.Prairie_Warbler\n",
            "Copied 30 images to data/train/175.Pine_Warbler\n",
            "Copied 28 images to data/valid/175.Pine_Warbler\n",
            "Copied 40 images to data/train/179.Tennessee_Warbler\n",
            "Copied 22 images to data/valid/179.Tennessee_Warbler\n",
            "Copied 27 images to data/train/171.Myrtle_Warbler\n",
            "Copied 17 images to data/valid/171.Myrtle_Warbler\n",
            "Copied 29 images to data/train/172.Nashville_Warbler\n",
            "Copied 31 images to data/valid/172.Nashville_Warbler\n",
            "Copied 28 images to data/train/164.Cerulean_Warbler\n",
            "Copied 24 images to data/valid/164.Cerulean_Warbler\n",
            "Copied 31 images to data/train/169.Magnolia_Warbler\n",
            "Copied 19 images to data/valid/169.Magnolia_Warbler\n",
            "Copied 26 images to data/train/167.Hooded_Warbler\n",
            "Copied 26 images to data/valid/167.Hooded_Warbler\n",
            "Copied 35 images to data/train/170.Mourning_Warbler\n",
            "Copied 33 images to data/valid/170.Mourning_Warbler\n",
            "Copied 38 images to data/train/166.Golden_winged_Warbler\n",
            "Copied 30 images to data/valid/166.Golden_winged_Warbler\n",
            "Copied 42 images to data/train/168.Kentucky_Warbler\n",
            "Copied 22 images to data/valid/168.Kentucky_Warbler\n",
            "Copied 39 images to data/train/165.Chestnut_sided_Warbler\n",
            "Copied 19 images to data/valid/165.Chestnut_sided_Warbler\n",
            "Copied 48 images to data/train/163.Cape_May_Warbler\n",
            "Copied 22 images to data/valid/163.Cape_May_Warbler\n",
            "Copied 43 images to data/train/161.Blue_winged_Warbler\n",
            "Copied 27 images to data/valid/161.Blue_winged_Warbler\n",
            "Copied 39 images to data/train/162.Canada_Warbler\n",
            "Copied 33 images to data/valid/162.Canada_Warbler\n",
            "Copied 39 images to data/train/154.Red_eyed_Vireo\n",
            "Copied 29 images to data/valid/154.Red_eyed_Vireo\n",
            "Copied 25 images to data/train/160.Black_throated_Blue_Warbler\n",
            "Copied 19 images to data/valid/160.Black_throated_Blue_Warbler\n",
            "Copied 37 images to data/train/156.White_eyed_Vireo\n",
            "Copied 31 images to data/valid/156.White_eyed_Vireo\n",
            "Copied 46 images to data/train/159.Black_and_white_Warbler\n",
            "Copied 24 images to data/valid/159.Black_and_white_Warbler\n",
            "Copied 38 images to data/train/155.Warbling_Vireo\n",
            "Copied 32 images to data/valid/155.Warbling_Vireo\n",
            "Copied 33 images to data/train/157.Yellow_throated_Vireo\n",
            "Copied 29 images to data/valid/157.Yellow_throated_Vireo\n",
            "Copied 42 images to data/train/158.Bay_breasted_Warbler\n",
            "Copied 22 images to data/valid/158.Bay_breasted_Warbler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arz5mDhfMhtq",
        "colab_type": "text"
      },
      "source": [
        "# preprocess images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "-MOD2sCeMhtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_image(x, size_target=None, flg_keep_aspect=False, rate_scale=1.0, flg_random_scale=False):\n",
        "\n",
        "    # convert to numpy array\n",
        "    if not isinstance(x, np.ndarray):\n",
        "        img = np.asarray(x)\n",
        "    else:\n",
        "        img = x\n",
        "\n",
        "    # calculate resize coefficients\n",
        "    if len(img.shape) == 4:\n",
        "        _o, size_height_img, size_width_img, _c , = img.shape\n",
        "        img = img[0]\n",
        "    elif len(img.shape) == 3:\n",
        "        size_height_img, size_width_img, _c , = img.shape\n",
        "\n",
        "    if len(size_target) == 1:\n",
        "        size_heigth_target = size_target\n",
        "        size_width_target = size_target\n",
        "    if len(size_target) == 2:\n",
        "        size_heigth_target = size_target[0]\n",
        "        size_width_target = size_target[1]\n",
        "    if size_target == None:\n",
        "        size_heigth_target = size_height_img * rate_scale \n",
        "        size_width_target = size_width_img * rate_scale \n",
        "\n",
        "    coef_height = 1\n",
        "    coef_width = 1\n",
        "    if size_height_img < size_heigth_target :\n",
        "        coef_height = size_heigth_target / size_height_img\n",
        "    if size_width_img < size_width_target :\n",
        "        coef_width = size_width_target / size_width_img\n",
        "\n",
        "    # calculate coeffieient to match small size to target size\n",
        "    ## scale coefficient if specified\n",
        "    low_scale = rate_scale\n",
        "    if flg_random_scale:\n",
        "        low_scale = 1.0\n",
        "    coef_max = max(coef_height, coef_width) * np.random.uniform(low=low_scale, high=rate_scale)\n",
        "\n",
        "    # resize image\n",
        "    size_height_resize = math.ceil(size_height_img*coef_max)\n",
        "    size_width_resize = math.ceil(size_width_img*coef_max)\n",
        "\n",
        "    # method_interpolation = cv2.INTER_LINEAR\n",
        "    method_interpolation = cv2.INTER_CUBIC\n",
        "    # method_interpolation = cv2.INTER_NEAREST\n",
        "\n",
        "    if flg_keep_aspect:\n",
        "        img_resized = cv2.resize(\n",
        "                            img\n",
        "                            , dsize=(size_width_resize, size_height_resize)\n",
        "                            , interpolation=method_interpolation\n",
        "                        )\n",
        "    else:\n",
        "        img_resized = cv2.resize(\n",
        "                            img\n",
        "                            , dsize=(\n",
        "                                int(size_width_target*np.random.uniform(low=low_scale, high=rate_scale))\n",
        "                                ,int(size_heigth_target*np.random.uniform(low=low_scale, high=rate_scale))\n",
        "                            )\n",
        "                            , interpolation=method_interpolation\n",
        "                        )\n",
        "    return img_resized\n",
        "\n",
        "def resize_images(images, **kwargs):\n",
        "    max_images = len(images)\n",
        "    for i in range(max_images):\n",
        "        images[i] = resize_image(images[i], **kwargs)\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uicMHHXiMhtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# crop image at the center\n",
        "def center_crop_image(x, size_target=(448,448)):\n",
        "\n",
        "    # convert to numpy array\n",
        "    if not isinstance(x, np.ndarray):\n",
        "        img = np.asarray(x)\n",
        "    else:\n",
        "        img = x\n",
        "\n",
        "    # set size\n",
        "    if len(size_target) == 1:\n",
        "        size_heigth_target = size_target\n",
        "        size_width_target = size_target\n",
        "    if len(size_target) == 2:\n",
        "        size_heigth_target = size_target[0]\n",
        "        size_width_target = size_target[1]\n",
        "\n",
        "    if len(img.shape) == 4:\n",
        "        _o, size_height_img, size_width_img, _c , = img.shape\n",
        "        img = img[0]\n",
        "    elif len(img.shape) == 3:\n",
        "        size_height_img, size_width_img, _c , = img.shape\n",
        "\n",
        "    # crop image\n",
        "    h_start = int((size_height_img - size_heigth_target) / 2)\n",
        "    w_start = int((size_width_img - size_width_target) / 2)\n",
        "    img_cropped = img[h_start:h_start+size_heigth_target, w_start:w_start+size_width_target, :]\n",
        "\n",
        "    return img_cropped\n",
        "\n",
        "\n",
        "\n",
        "# crop image of fixed-size from random point of top-left corner\n",
        "def random_crop_image(x, size_target=(448,448)):\n",
        "\n",
        "    # convert to numpy array\n",
        "    if not isinstance(x, np.ndarray):\n",
        "        img = np.asarray(x)\n",
        "    else:\n",
        "        img = x\n",
        "\n",
        "    # set size\n",
        "    if len(size_target) == 1:\n",
        "        size_heigth_target = size_target\n",
        "        size_width_target = size_target\n",
        "    if len(size_target) == 2:\n",
        "        size_heigth_target = size_target[0]\n",
        "        size_width_target = size_target[1]\n",
        "\n",
        "    if len(img.shape) == 4:\n",
        "        _o, size_height_img, size_width_img, _c , = img.shape\n",
        "        img = img[0]\n",
        "    elif len(img.shape) == 3:\n",
        "        size_height_img, size_width_img, _c , = img.shape\n",
        "\n",
        "    # crop image\n",
        "    margin_h = (size_height_img - size_heigth_target)\n",
        "    margin_w = (size_width_img - size_width_target)\n",
        "    h_start = 0 \n",
        "    w_start = 0\n",
        "    if margin_h != 0:\n",
        "        h_start = np.random.randint(low=0, high=margin_h)\n",
        "    if margin_w != 0:\n",
        "        w_start = np.random.randint(low=0, high=margin_w) \n",
        "    img_cropped = img[h_start:h_start+size_heigth_target, w_start:w_start+size_width_target, :]\n",
        "\n",
        "    return img_cropped\n",
        "\n",
        "\n",
        "\n",
        "# flip image horizontally \n",
        "def horizontal_flip_image(x):\n",
        "    \n",
        "    if np.random.random() >= 0.5:\n",
        "        return x[:,::-1,:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# feature-wise normalization\n",
        "def normalize_image(x, mean=(0., 0., 0.), std=(1.0, 1.0, 1.0)) :\n",
        "    \n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "\n",
        "    if len(x.shape) == 4:\n",
        "        for dim in range(3):\n",
        "            x[:,:,:,dim] = ( x[:,:,:,dim] - mean[dim] ) / std[dim]\n",
        "    if len(x.shape) == 3:\n",
        "        for dim in range(3):\n",
        "            x[:,:,dim] = ( x[:,:,dim] - mean[dim] ) / std[dim]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def check_images(images):\n",
        "    fig=plt.figure(figsize=(8, 8))\n",
        "    columns = 3\n",
        "    rows = 3\n",
        "    for i in range(1, columns*rows+1):\n",
        "        fig.add_subplot(rows, columns, i)\n",
        "        plt.imshow(images[i-1].astype('uint8'))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": false,
        "id": "jSDXb2CJMht1",
        "colab_type": "text"
      },
      "source": [
        "### original images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "k5_z3bVqMht2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check_images(trainval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": false,
        "id": "QW6wL7QqMht6",
        "colab_type": "text"
      },
      "source": [
        "### resized images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgRC69CeMht8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # resize images to generate cropped 448x448 images while keeping aspect ratio\n",
        "# trainval_resized = resize_images(trainval, size_target=(448,448), flg_keep_aspect=True)\n",
        "# check_images(trainval_resized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": false,
        "id": "YhNIkI7xMhuA",
        "colab_type": "text"
      },
      "source": [
        "### flipped images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "deKlFggkMhuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainval_resized_flipped = trainval_resized.copy()\n",
        "# for i in range(9):\n",
        "#     trainval_resized_flipped[i] = horizontal_flip_image(trainval_resized_flipped[i])\n",
        "# check_images(trainval_resized_flipped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqi-C_u9MhuF",
        "colab_type": "text"
      },
      "source": [
        "### center cropped images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "n5KlqRWbMhuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainval_resized_cropped = trainval_resized.copy()\n",
        "for i in range(9):\n",
        "    trainval_resized_cropped[i] = center_crop_image(trainval_resized_cropped[i])\n",
        "check_images(trainval_resized_cropped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qD7MfIbMhuK",
        "colab_type": "text"
      },
      "source": [
        "### random cropped images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiQFG93LMhuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainval_resized_cropped = trainval_resized.copy()\n",
        "for i in range(9):\n",
        "    trainval_resized_cropped[i] = random_crop_image(trainval_resized_cropped[i])\n",
        "check_images(trainval_resized_cropped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvwAI4X1MhuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4xhFJMnMhuT",
        "colab_type": "text"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkF5LqokMhuV",
        "colab_type": "text"
      },
      "source": [
        "### bypass keras preprocessing for resizing images while keeping aspect ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8cmVyWGMhuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as backend\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import array_to_img\n",
        "\n",
        "class DirectoryIterator(keras.preprocessing.image.DirectoryIterator):\n",
        "    def _get_batches_of_transformed_samples(self, index_array):\n",
        "        \n",
        "        batch_x = np.zeros(\n",
        "            (len(index_array),) + self.image_shape,\n",
        "            dtype=backend.floatx())\n",
        "        grayscale = self.color_mode == 'grayscale'\n",
        "        \n",
        "        # build batch of image data\n",
        "        for i, j in enumerate(index_array):\n",
        "            fname = self.filenames[j]\n",
        "            img = load_img(os.path.join(self.directory, fname),\n",
        "                           grayscale=grayscale,\n",
        "                           target_size=None,\n",
        "                           interpolation=self.interpolation)\n",
        "            x = img_to_array(img, data_format=self.data_format)\n",
        "            # Pillow images should be closed after `load_img`,\n",
        "            # but not PIL images.\n",
        "            if hasattr(img, 'close'):\n",
        "                img.close()\n",
        "            x = self.image_data_generator.standardize(x)\n",
        "            batch_x[i] = x\n",
        "            \n",
        "        # optionally save augmented images to disk for debugging purposes\n",
        "        if self.save_to_dir:\n",
        "            for i, j in enumerate(index_array):\n",
        "                img = array_to_img(batch_x[i], self.data_format, scale=True)\n",
        "                fname = '{prefix}_{index}_{hash}.{format}'.format(\n",
        "                    prefix=self.save_prefix,\n",
        "                    index=j,\n",
        "                    hash=np.random.randint(1e7),\n",
        "                    format=self.save_format)\n",
        "                img.save(os.path.join(self.save_to_dir, fname))\n",
        "                \n",
        "        # build batch of labels\n",
        "        if self.class_mode == 'input':\n",
        "            batch_y = batch_x.copy()\n",
        "        elif self.class_mode == 'sparse':\n",
        "            batch_y = self.classes[index_array]\n",
        "        elif self.class_mode == 'binary':\n",
        "            batch_y = self.classes[index_array].astype(backend.floatx())\n",
        "        elif self.class_mode == 'categorical':\n",
        "            batch_y = np.zeros(\n",
        "                (len(batch_x), self.num_classes),\n",
        "                dtype=backend.floatx())\n",
        "            for i, label in enumerate(self.classes[index_array]):\n",
        "                batch_y[i, label] = 1.\n",
        "        else:\n",
        "            return batch_x\n",
        "        \n",
        "        return batch_x, batch_y\n",
        "\n",
        "\n",
        "class ImageDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n",
        "    def flow_from_directory(self, directory,\n",
        "                            target_size=(256, 256), color_mode='rgb',\n",
        "                            classes=None, class_mode='categorical',\n",
        "                            batch_size=16, shuffle=True, seed=None,\n",
        "                            save_to_dir=None,\n",
        "                            save_prefix='',\n",
        "                            save_format='png',\n",
        "                            follow_links=False,\n",
        "                            subset=None,\n",
        "                            interpolation='nearest'):\n",
        "\n",
        "        return DirectoryIterator(\n",
        "            directory, self,\n",
        "            target_size=target_size, color_mode=color_mode,\n",
        "            classes=classes, class_mode=class_mode,\n",
        "            data_format=self.data_format,\n",
        "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=save_prefix,\n",
        "            save_format=save_format,\n",
        "            follow_links=follow_links,\n",
        "            subset=subset,\n",
        "            interpolation=interpolation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTCadgQxMhua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(\n",
        "    path_data_train=None\n",
        "    ,path_data_valid=None/\n",
        "\n",
        "    ,size_width=448\n",
        "    ,size_heigth=448\n",
        "    ,size_mini_batch=16\n",
        "    \n",
        "    ,flg_debug=False\n",
        "    ,**kwargs\n",
        "):\n",
        "                    \n",
        "    # set preprocessing functions       \n",
        "    func_train = lambda x :normalize_image(\n",
        "                                random_crop_image(\n",
        "                                    horizontal_flip_image(\n",
        "                                        resize_image(x, size_target=(size_heigth,size_width), flg_keep_aspect=True)\n",
        "                                    )\n",
        "                                )\n",
        "                                ,mean=[123.82988033, 127.3509729, 110.25606303]\n",
        "                            )\n",
        "    func_valid = lambda x :normalize_image(\n",
        "                                center_crop_image(\n",
        "                                    resize_image(x, size_target=(size_heigth,size_width), flg_keep_aspect=True)\n",
        "                                )\n",
        "                                ,mean=[123.82988033, 127.3509729, 110.25606303]\n",
        "                            )\n",
        "    \n",
        "    # set image_data_generator \n",
        "    gen_train = ImageDataGenerator(   \n",
        "                    preprocessing_function=func_train\n",
        "                )\n",
        "\n",
        "    gen_valid = ImageDataGenerator(\n",
        "                    preprocessing_function=func_valid\n",
        "                )\n",
        "\n",
        "    gen_dir_train = gen_train.flow_from_directory(\n",
        "                            path_data_train\n",
        "                            ,target_size=(size_heigth, size_width)\n",
        "                            ,batch_size=size_mini_batch\n",
        "                        )\n",
        "\n",
        "    gen_dir_valid = gen_valid.flow_from_directory(\n",
        "                            path_data_valid\n",
        "                            ,target_size=(size_heigth, size_width)\n",
        "                            ,batch_size=size_mini_batch\n",
        "                            ,shuffle=False\n",
        "                    )\n",
        "\n",
        "    return gen_dir_train, gen_dir_valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mklm-ijaMhue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_dir_train, gen_dir_valid = load_data(\n",
        "                                    path_data_train=PATH_DATA_ROOT_CUB200+\"/splitted/train\"\n",
        "                                    ,path_data_valid=PATH_DATA_ROOT_CUB200+\"/splitted/valid\"\n",
        "                                    ,size_mini_batch=9\n",
        "                                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgDtcgpRMhui",
        "colab_type": "text"
      },
      "source": [
        "### check preprocessed training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l28QWGh0Mhuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = gen_dir_train.next()\n",
        "check_images(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3haUBi7GMhum",
        "colab_type": "text"
      },
      "source": [
        "# build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boqy3skwMhun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.initializers import glorot_normal\n",
        "\n",
        "def outer_product(x):\n",
        "    \"\"\"\n",
        "    calculate outer-products of 2 tensors\n",
        "\n",
        "        args \n",
        "            x\n",
        "                list of 2 tensors\n",
        "                , assuming each of which has shape = (size_minibatch, total_pixels, size_filter)\n",
        "    \"\"\"\n",
        "    return keras.backend.batch_dot(\n",
        "                x[0]\n",
        "                , x[1]\n",
        "                , axes=[1,1]\n",
        "            ) / x[0].get_shape().as_list()[1] \n",
        "\n",
        "def signed_sqrt(x):\n",
        "    \"\"\"\n",
        "    calculate element-wise signed square root\n",
        "\n",
        "        args\n",
        "            x\n",
        "                a tensor\n",
        "    \"\"\"\n",
        "    return keras.backend.sign(x) * keras.backend.sqrt(keras.backend.abs(x) + 1e-9)\n",
        "\n",
        "def L2_norm(x, axis=-1):\n",
        "    \"\"\"\n",
        "    calculate L2-norm\n",
        "\n",
        "        args \n",
        "            x\n",
        "                a tensor\n",
        "    \"\"\"\n",
        "    return keras.backend.l2_normalize(x, axis=axis)\n",
        "\n",
        "\n",
        "def build_model(\n",
        "    size_heigth=448\n",
        "    ,size_width=448\n",
        "    ,no_class=200\n",
        "    ,no_last_layer_backbone=17\n",
        "    \n",
        "    ,name_optimizer=\"sgd\"\n",
        "    ,rate_learning=1.0\n",
        "    ,rate_decay_learning=0.0\n",
        "    ,rate_decay_weight=0.0\n",
        "    \n",
        "    ,name_initializer=\"glorot_normal\"\n",
        "    ,name_activation_logits=\"softmax\"\n",
        "    ,name_loss=\"categorical_crossentropy\"\n",
        "\n",
        "    ,flg_debug=False\n",
        "    ,**kwargs\n",
        "):\n",
        "    \n",
        "    keras.backend.clear_session()\n",
        "    \n",
        "    print(\"-------------------------------\")\n",
        "    print(\"parameters:\")\n",
        "    for key, val in locals().items():\n",
        "        if not val == None and not key == \"kwargs\":\n",
        "            print(\"\\t\", key, \"=\",  val)\n",
        "    print(\"-------------------------------\")\n",
        "    \n",
        "    ### \n",
        "    ### load pre-trained model\n",
        "    ###\n",
        "    tensor_input = keras.layers.Input(shape=[size_heigth,size_width,3])\n",
        "    model_detector = keras.applications.vgg16.VGG16(\n",
        "                            input_tensor=tensor_input\n",
        "                            , include_top=False\n",
        "                            , weights='imagenet'\n",
        "                        )\n",
        "    \n",
        "\n",
        "    ### \n",
        "    ### bi-linear pooling\n",
        "    ###\n",
        "\n",
        "    # extract features from detector\n",
        "    x_detector = model_detector.layers[no_last_layer_backbone].output\n",
        "    shape_detector = model_detector.layers[no_last_layer_backbone].output_shape\n",
        "    if flg_debug:\n",
        "        print(\"shape_detector : {}\".format(shape_detector))\n",
        "\n",
        "    # extract features from extractor , same with detector for symmetry DxD model\n",
        "    shape_extractor = shape_detector\n",
        "    x_extractor = x_detector\n",
        "    if flg_debug:\n",
        "        print(\"shape_extractor : {}\".format(shape_extractor))\n",
        "        \n",
        "    \n",
        "    # rehape to (minibatch_size, total_pixels, filter_size)\n",
        "    x_detector = keras.layers.Reshape(\n",
        "            [\n",
        "                shape_detector[1] * shape_detector[2] , shape_detector[-1]\n",
        "            ]\n",
        "        )(x_detector)\n",
        "    if flg_debug:\n",
        "        print(\"x_detector shape after rehsape ops : {}\".format(x_detector.shape))\n",
        "        \n",
        "    x_extractor = keras.layers.Reshape(\n",
        "            [\n",
        "                shape_extractor[1] * shape_extractor[2] , shape_extractor[-1]\n",
        "            ]\n",
        "        )(x_extractor)\n",
        "    if flg_debug:\n",
        "        print(\"x_extractor shape after rehsape ops : {}\".format(x_extractor.shape))\n",
        "        \n",
        "        \n",
        "    # outer products of features, output shape=(minibatch_size, filter_size_detector*filter_size_extractor)\n",
        "    x = keras.layers.Lambda(outer_product)(\n",
        "        [x_detector, x_extractor]\n",
        "    )\n",
        "    if flg_debug:\n",
        "        print(\"x shape after outer products ops : {}\".format(x.shape))\n",
        "        \n",
        "        \n",
        "    # rehape to (minibatch_size, filter_size_detector*filter_size_extractor)\n",
        "    x = keras.layers.Reshape([shape_detector[-1]*shape_extractor[-1]])(x)\n",
        "    if flg_debug:\n",
        "        print(\"x shape after rehsape ops : {}\".format(x.shape))\n",
        "        \n",
        "        \n",
        "    # signed square-root \n",
        "    x = keras.layers.Lambda(signed_sqrt)(x)\n",
        "    if flg_debug:\n",
        "        print(\"x shape after signed-square-root ops : {}\".format(x.shape))\n",
        "        \n",
        "    # L2 normalization\n",
        "    x = keras.layers.Lambda(L2_norm)(x)\n",
        "    if flg_debug:\n",
        "        print(\"x shape after L2-Normalization ops : {}\".format(x.shape))\n",
        "\n",
        "\n",
        "\n",
        "    ### \n",
        "    ### attach FC-Layer\n",
        "    ###\n",
        "\n",
        "    if name_initializer != None:\n",
        "            name_initializer = eval(name_initializer+\"()\")\n",
        "            \n",
        "    x = keras.layers.Dense(\n",
        "            units=no_class\n",
        "            ,kernel_regularizer=keras.regularizers.l2(rate_decay_weight)\n",
        "            ,kernel_initializer=name_initializer\n",
        "        )(x)\n",
        "    if flg_debug:\n",
        "        print(\"x shape after Dense ops : {}\".format(x.shape))\n",
        "    tensor_prediction = keras.layers.Activation(name_activation_logits)(x)\n",
        "    if flg_debug:\n",
        "        print(\"prediction shape : {}\".format(tensor_prediction.shape))\n",
        "\n",
        "        \n",
        "\n",
        "    ### \n",
        "    ### compile model\n",
        "    ###\n",
        "    model_bilinear = keras.models.Model(\n",
        "                        inputs=[tensor_input]\n",
        "                        , outputs=[tensor_prediction]\n",
        "                    )\n",
        "    \n",
        "    \n",
        "    # fix pre-trained weights\n",
        "    for layer in model_detector.layers:\n",
        "        layer.trainable = False\n",
        "        \n",
        "        \n",
        "    # define optimizers\n",
        "    opt_adam = keras.optimizers.adam(\n",
        "                    lr=rate_learning\n",
        "                    , decay=rate_decay_learning\n",
        "                )\n",
        "    opt_rms = keras.optimizers.RMSprop(\n",
        "                    lr=rate_learning\n",
        "                    , decay=rate_decay_learning\n",
        "                )\n",
        "    opt_sgd = keras.optimizers.SGD(\n",
        "                    lr=rate_learning\n",
        "                    , decay=rate_decay_learning\n",
        "                    , momentum=0.9\n",
        "                    , nesterov=False\n",
        "                )\n",
        "    optimizers ={\n",
        "        \"adam\":opt_adam\n",
        "        ,\"rmsprop\":opt_rms\n",
        "        ,\"sgd\":opt_sgd\n",
        "    }\n",
        "    \n",
        "    model_bilinear.compile(\n",
        "        loss=name_loss\n",
        "        , optimizer=optimizers[name_optimizer]\n",
        "        , metrics=[\"categorical_accuracy\"]\n",
        "    )\n",
        "    \n",
        "    \n",
        "    \n",
        "    if flg_debug:\n",
        "        model_bilinear.summary()\n",
        "    \n",
        "    return model_bilinear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVUXLXksMhus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "            # number of output classes, 200 for CUB200\n",
        "            no_class = NO_CLASS\n",
        "\n",
        "            # pretrained model specification, using VGG16\n",
        "            # \"block5_conv3 \"\n",
        "            ,no_last_layer_backbone = 17\n",
        "    \n",
        "            # training parametes\n",
        "            ,rate_learning=1.0\n",
        "            ,rate_decay_weight=1e-8\n",
        "    \n",
        "            ,flg_debug=True\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS36UFwwMhuv",
        "colab_type": "text"
      },
      "source": [
        "# train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Fg0KHRMhux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(\n",
        "        model=None\n",
        "        ,name_model=\"BCNN_keras\"\n",
        "        ,gen_dir_train=None\n",
        "        ,gen_dir_valid=None\n",
        "        ,max_epoch=50\n",
        "    ):\n",
        "    \n",
        "    path_model = \"./model/{}/\".format(name_model)\n",
        "    if not os.path.exists(path_model):\n",
        "        os.mkdir(path_model)\n",
        "        \n",
        "    now = time.strftime(\"%Y%m%d%H%M%S\", time.localtime())\n",
        "        \n",
        "    # callback setting\n",
        "    callback_logger = keras.callbacks.CSVLogger(\n",
        "                            path_model +  \"log_training_{}.csv\".format(now)\n",
        "                            , separator=','\n",
        "                            , append=False\n",
        "                        )\n",
        "    callack_saver = keras.callbacks.ModelCheckpoint(\n",
        "                        path_model\n",
        "                            + \"E[{epoch:02d}]\"\n",
        "                            + \"_LOS[{val_loss:.3f}]\"\n",
        "                            + \"_ACC[{val_categorical_accuracy:.3f}]\"\n",
        "                            + \".hdf5\" \n",
        "                        , monitor='val_loss'\n",
        "                        , verbose=0\n",
        "                        , mode='auto'\n",
        "                        , period=10\n",
        "                        , save_best_only=True\n",
        "                    )\n",
        "    callback_reducer = keras.callbacks.ReduceLROnPlateau(\n",
        "                                monitor='val_loss'\n",
        "                                , factor=0.5\n",
        "                                , patience=5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
        "                                , min_lr=1e-6\n",
        "                                , min_delta=1e-3\n",
        "                            )\n",
        "    callback_stopper = keras.callbacks.EarlyStopping(\n",
        "                            monitor='val_loss'\n",
        "                            , min_delta=1e-3\n",
        "                            , patience=10\n",
        "                            , verbose=0\n",
        "                            , mode='auto'\n",
        "                        )\n",
        "    list_callback = [\n",
        "        callback_logger\n",
        "        ,callack_saver\n",
        "        ,callback_reducer\n",
        "        ,callback_stopper\n",
        "    ]\n",
        "            \n",
        "    hist = model.fit_generator(\n",
        "                gen_dir_train\n",
        "                , epochs=max_epoch\n",
        "                , validation_data=gen_dir_valid\n",
        "                ,callbacks=list_callback\n",
        "                ,workers=3\n",
        "                ,verbose=1\n",
        "            )\n",
        "        \n",
        "    model.save_weights(\n",
        "        path_model\n",
        "            + \"E[{}]\".format(len(hist.history['val_loss']))\n",
        "            + \"_LOS[{:.3f}]\".format(hist.history['val_loss'][-1])\n",
        "            + \"_ACC[{:.3f}]\".format(hist.history['val_categorical_accuracy'][-1])\n",
        "            + \".h5\" \n",
        "    )\n",
        "    \n",
        "    return hist                                              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mwmBuuddMhu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist =train_model(\n",
        "            model=model\n",
        "            ,gen_dir_train=gen_dir_train\n",
        "            ,gen_dir_valid=gen_dir_valid\n",
        "            ,max_epoch=1\n",
        "\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noXAtat5Mhu3",
        "colab_type": "text"
      },
      "source": [
        "# finetune only FC-layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZFelZZNgMhu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist =train_model(\n",
        "            model=model\n",
        "            ,gen_dir_train=gen_dir_train\n",
        "            ,gen_dir_valid=gen_dir_valid\n",
        "            ,max_epoch=99\n",
        "\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_DYhUyxMhu7",
        "colab_type": "text"
      },
      "source": [
        "# finetune ALL-layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CffHIWTEMhu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now all layers are trainable\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# change LR\n",
        "opt_sgd = keras.optimizers.SGD(\n",
        "                lr=1e-3\n",
        "                , decay=1e-9\n",
        "                , momentum=0.9\n",
        "                , nesterov=False\n",
        "            )\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\"\n",
        "    , optimizer=opt_sgd\n",
        "    , metrics=[\"categorical_accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MRZ8Z_QMhu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist =train_model(\n",
        "            model=model\n",
        "            ,gen_dir_train=gen_dir_train\n",
        "            ,gen_dir_valid=gen_dir_valid\n",
        "            ,max_epoch=1\n",
        "\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9_pHGqMMhvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist =train_model(\n",
        "            model=model\n",
        "            ,gen_dir_train=gen_dir_train\n",
        "            ,gen_dir_valid=gen_dir_valid\n",
        "            ,max_epoch=33\n",
        "\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8fE1k2-MhvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}